<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding Spiders, Bots, and Webcrawlers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: auto;
            background: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h2 {
            color: #007BFF;
        }
        p {
            line-height: 1.6;
        }
        .accordion {
            background-color: #eee;
            color: #444;
            cursor: pointer;
            padding: 18px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 15px;
            transition: 0.4s;
        }
        .active, .accordion:hover {
            background-color: #ccc;
        }
        .panel {
            padding: 0 18px;
            background-color: white;
            display: none;
            overflow: hidden;
        }
    </style>
</head>
<body>

<div class="container">
    <h1>Understanding Spiders, Bots, and Webcrawlers</h1>
    
    <button class="accordion">1. Starting with URLs</button>
    <div class="panel">
        <p>Crawlers start their journey from a list of web addresses (URLs), including previous crawl data, sitemaps, or links on pages.</p>
    </div>
    
    <button class="accordion">2. Visiting and Reading Web Pages</button>
    <div class="panel">
        <p>Crawlers "read" the page's content by downloading its HTML code, focusing on the code rather than the visual appearance.</p>
    </div>
    
    <button class="accordion">3. Extracting Links</button>
    <div class="panel">
        <p>While examining the HTML, the crawler looks for links to other pages to determine its next destinations.</p>
    </div>
    
    <button class="accordion">4. Following Links</button>
    <div class="panel">
        <p>The crawler follows these links, repeating the process of reading and extracting links from each new page.</p>
    </div>
    
    <button class="accordion">5. Avoiding Duplication</button>
    <div class="panel">
        <p>To avoid visiting the same page multiple times, crawlers keep track of where they've been using a database of URLs.</p>
    </div>
    
    <button class="accordion">6. Respecting Rules</button>
    <div class="panel">
        <p>Websites can use `robots.txt` to give instructions to crawlers, indicating which pages they can or cannot visit.</p>
    </div>
    
    <button class="accordion">7. Indexing Content</button>
    <div class="panel">
        <p>The goal is to index web content, analyzing and storing it in a way that makes it easily retrievable for search queries.</p>
    </div>
    
    <button class="accordion">8. Continuous Process</button>
    <div class="panel">
        <p>The internet's constant evolution means crawlers are always at work, revisiting sites to check for updates or new content.</p>
    </div>

</div>

<script>
    var acc = document.getElementsByClassName("accordion");
    var i;

    for (i = 0; i < acc.length; i++) {
        acc[i].addEventListener("click", function() {
            this.classList.toggle("active");
            var panel = this.nextElementSibling;
            if (panel.style.display === "block") {
                panel.style.display = "none";
            } else {
                panel.style.display = "block";
            }
        });
    }
</script>

</body>
</html>
